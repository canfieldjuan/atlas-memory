# Atlas Memory — Graphiti GraphRAG Server (local deployment)
# Knowledge graph API with Neo4j backend, 100% local inference

FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for layer caching
COPY graphiti-wrapper/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Copy graphiti wrapper code
COPY graphiti-wrapper/ ./graphiti-wrapper/

# Set working directory for the server
WORKDIR /app/graphiti-wrapper

# Default port
ENV PORT=8000

# Expose port
EXPOSE 8000

# Health check — longer start-period for first-run model downloads
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:${PORT:-8000}/health || exit 1

# Run graphiti server
CMD python -m uvicorn main:app --host 0.0.0.0 --port ${PORT:-8000}
